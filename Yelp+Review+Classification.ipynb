{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yelp Reviews Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This exercise uses a small subset of the data from Kaggle's [Yelp Business Rating Prediction](https://www.kaggle.com/c/yelp-recsys-2013) competition.\n",
    "\n",
    "**Description of the data:**\n",
    "\n",
    "- **`yelp.csv`** contains the dataset. It is stored in the repository (in the **`data`** directory), so there is no need to download anything from the Kaggle website.\n",
    "- Each observation (row) in this dataset is a review of a particular business by a particular user.\n",
    "- The **stars** column is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "- The **text** column is the text of the review.\n",
    "\n",
    "**Goal:** Predict the star rating of a review using **only** the review text.\n",
    "\n",
    "**Tip:** After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Task 1\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"D:\\Machine Learning\\pycon-2016-tutorial-master\\data\\yelp.csv\")\n",
    "\n",
    "\n",
    "# print(data.iloc[0:3,[4,3]])\n",
    "\n",
    "df1 = data.loc[:,['text','stars']]\n",
    "\n",
    "\n",
    "\n",
    "# Read **`yelp.csv`** into a pandas DataFrame and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "1  I have no idea why some people give bad review...      5\n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...      5\n",
       "4  General Manager Scott Petello is a good egg!!!...      5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 2\n",
    "\n",
    "# Create a new DataFrame that only contains the **5-star** and **1-star** reviews.\n",
    "\n",
    "\n",
    "df2 = df1[(df1['stars'] == 5) | (df1['stars'] == 1)]\n",
    "\n",
    "\n",
    "df2[1:4]\n",
    "\n",
    "\n",
    "#  **Hint:** [How do I apply multiple filter criteria to a pandas DataFrame?](http://nbviewer.jupyter.org/github/justmarkham/pandas-videos/blob/master/pandas.ipynb#9.-How-do-I-apply-multiple-filter-criteria-to-a-pandas-DataFrame%3F-%28video%29) explains how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n",
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "## Task 3\n",
    "\n",
    "## Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the **review text** as the only feature and the **star rating** as the response.\n",
    "\n",
    "X = df2.text\n",
    "y=  df2.stars\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "#- **Hint:** Keep in mind that X should be a pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Task 4\n",
    "\n",
    "## Use CountVectorizer to create **document-term matrices** from X_train and X_test.\n",
    "\n",
    "# Instantiate the Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',max_df=0.5,min_df=2)\n",
    "\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16 ms\n",
      "0.922700587084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[148,  36],\n",
       "       [ 43, 795]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 5 Building and evaluating a model\n",
    "\n",
    "## Use multinomial Naive Bayes to **predict the star rating** for the reviews in the testing set, and then **calculate the accuracy** and **print the confusion matrix**.\n",
    "\n",
    "## **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains how to interpret both classification accuracy and the confusion matrix.\n",
    "\n",
    "# https://www.youtube.com/watch?v=os-NaA0ldGs&list=PLBv09BD7ez_6CxkuiFTbL3jsn2Qd1IU7B&index=1 \n",
    "# - Link to understand different Gaussian distribution\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb =  MultinomialNB()\n",
    "\n",
    "%time nb.fit(X_train_dtm,y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5    838\n",
      "1    184\n",
      "Name: stars, dtype: int64\n",
      "0.8199608610567515\n"
     ]
    }
   ],
   "source": [
    "## Task 6 (Challenge)\n",
    "\n",
    "\n",
    "## Calculate the **null accuracy**, which is the classification accuracy that could be achieved by always predicting the most frequent class.\n",
    "\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "print(1- (184/(838+184)))\n",
    "\n",
    "##- **Hint:** [Evaluating a classification model](https://github.com/justmarkham/scikit-learn-videos/blob/master/09_classification_metrics.ipynb) explains null accuracy and demonstrates two ways to calculate it, though only one of those ways will work in this case. Alternatively, you can come up with your own method to calculate null accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If you like the stuck up Scottsdale vibe this is a good place for you. The food isn't impressive. Nice outdoor seating.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 7 (Challenge)\n",
    "\n",
    "X_test[y_test < y_pred_class].head(10)\n",
    "\n",
    "# 1-star reviews incorrectly classified as 5-star reviews\n",
    "X_test[1781] # Model is reacting to positive words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8495)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Task 8 (Challenge)\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)\n",
    "nb.feature_count_.shape\n",
    "# Calculate which 10 tokens are the most predictive of **5-star reviews**, and which 10 tokens are the most predictive of **1-star reviews**.\n",
    "\n",
    "# - **Hint:** Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the `feature_count_` and `class_count_` attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store the number of times each token appears across each class\n",
    "one_star_token_count = nb.feature_count_[0, :]\n",
    "\n",
    "five_star_token_count = nb.feature_count_[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = pd.DataFrame({'token':X_train_tokens, 'one_star':one_star_token_count, 'five_star':five_star_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>42.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00am</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00pm</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       five_star  one_star\n",
       "token                     \n",
       "00          42.0      29.0\n",
       "000          8.0       7.0\n",
       "00am         5.0       6.0\n",
       "00pm         7.0       4.0\n",
       "01           5.0       4.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add 1 to one-star and five-star counts to avoid dividing by 0\n",
    "tokens['one_star'] = tokens.one_star + 1\n",
    "tokens['five_star'] = tokens.five_star + 1\n",
    "tokens.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  565.  2499.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150133.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first number is one-star reviews, second number is five-star reviews\n",
    "print(nb.class_count_)\n",
    "sum(tokens['five_star'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert the one-star and five-star counts into frequencies\n",
    "tokens['one_star'] = tokens.one_star / nb.class_count_[0]\n",
    "tokens['five_star'] = tokens.five_star / nb.class_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of five-star to one-star for each token\n",
    "tokens['five_star_ratio'] = tokens.five_star / tokens.one_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five_star</th>\n",
       "      <th>one_star</th>\n",
       "      <th>five_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.098840</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>11.168868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.078031</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>11.021909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.138856</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>8.717042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.186074</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>7.509432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>0.115246</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>5.426170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flavors</th>\n",
       "      <td>0.044818</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>5.064426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.025610</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>4.823263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.601841</td>\n",
       "      <td>0.127434</td>\n",
       "      <td>4.722778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>0.108443</td>\n",
       "      <td>0.023009</td>\n",
       "      <td>4.713116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>0.340136</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>4.687241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five_star  one_star  five_star_ratio\n",
       "token                                          \n",
       "perfect     0.098840  0.008850        11.168868\n",
       "fantastic   0.078031  0.007080        11.021909\n",
       "favorite    0.138856  0.015929         8.717042\n",
       "amazing     0.186074  0.024779         7.509432\n",
       "awesome     0.115246  0.021239         5.426170\n",
       "flavors     0.044818  0.008850         5.064426\n",
       "yum         0.025610  0.005310         4.823263\n",
       "great       0.601841  0.127434         4.722778\n",
       "excellent   0.108443  0.023009         4.713116\n",
       "love        0.340136  0.072566         4.687241"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sort_values('five_star_ratio', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 (Challenge)\n",
    "\n",
    "Up to this point, we have framed this as a **binary classification problem** by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a **5-class classification problem**.\n",
    "\n",
    "Here are the steps:\n",
    "\n",
    "- Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "- Split X and y into training and testing sets.\n",
    "- Create document-term matrices using CountVectorizer.\n",
    "- Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "- Print the confusion matrix, and comment on the results. (This [Stack Overflow answer](http://stackoverflow.com/a/30748053/1636598) explains how to read a multi-class confusion matrix.)\n",
    "- Print the [classification report](http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report), and comment on the results. If you are unfamiliar with the terminology it uses, research the terms, and then try to figure out how to calculate these metrics manually from the confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"D:\\Machine Learning\\pycon-2016-tutorial-master\\data\\yelp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X and y using the original DataFrame. (y should contain 5 different classes.)\n",
    "\n",
    "df1 = data.loc[:,['text','stars']]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500,)\n",
      "(2500,)\n",
      "(7500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Split X and y into training and testing sets.\n",
    "\n",
    "X = df1.text\n",
    "y=  df1.stars\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create document-term matrices using CountVectorizer.\n",
    "# Instantiate the Vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english',max_df=0.5,min_df=2)\n",
    "\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 22 ms\n"
     ]
    }
   ],
   "source": [
    "# Calculate the testing accuracy of a Multinomial Naive Bayes model.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb =  MultinomialNB()\n",
    "\n",
    "%time nb.fit(X_train_dtm,y_train)\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 84,  34,  32,  24,  11],\n",
       "       [ 36,  48,  56,  71,  23],\n",
       "       [ 14,  18,  93, 196,  44],\n",
       "       [ 17,  13,  46, 571, 237],\n",
       "       [ 17,   7,  18, 346, 444]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the testing accuracy with the null accuracy, and comment on the results.\n",
    "\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test,y_pred_class))\n",
    "\n",
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.3536\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the null accuracy\n",
    "y_test.value_counts().head(1) / y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **Precision** answers the question: \"When a given class is predicted, how often are those predictions correct?\" To calculate the precision for class 1, for example, you divide 55 by the sum of the first column of the confusion matrix.\n",
    "# manually calculate the precision for class 1\n",
    "precision = 55 / float(55 + 28 + 5 + 7 + 6)\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2972972972972973\n"
     ]
    }
   ],
   "source": [
    "# **Recall** answers the question: \"When a given class is the true class, how often is that class predicted?\" To calculate the recall for class 1, for example, you divide 55 by the sum of the first row of the confusion matrix.\n",
    "# manually calculate the recall for class 1\n",
    "recall = 55 / float(55 + 14 + 24 + 65 + 27)\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# **F1 score** is a weighted average of precision and recall.\n",
    "# manually calculate the F1 score for class 1\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "**Support** answers the question: \"How many observations exist for which a given class is the true class?\" To calculate the support for class 1,\n",
    "for example, you sum the first row of the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# manually calculate the support for class 1\n",
    "support = 55 + 14 + 24 + 65 + 27\n",
    "print(support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report comments:**\n",
    "\n",
    "- Class 1 has low recall, meaning that the model has a hard time detecting the 1-star reviews, but high precision, meaning that when the model predicts a review is 1-star, it's usually correct.\n",
    "- Class 5 has high recall and precision, probably because 5-star reviews have polarized language, and because the model has a lot of observations to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
